---
title: "Realtime Streams"
sidebarTitle: "Streams"
description: "Stream data in realtime from your Trigger.dev tasks to your frontend or backend applications."
---

Realtime Streams allow you to pipe streaming data from your Trigger.dev tasks to your frontend or backend applications in real-time. This is perfect for use cases like streaming AI completions, progress updates, or any continuous data flow.

<Note>
  Streams v2 requires SDK version **4.1.0 or later**. Make sure to upgrade your `@trigger.dev/sdk`
  and `@trigger.dev/react-hooks` packages to use these features. If you're on an earlier version,
  see the [metadata.stream()](/runs/metadata#stream) documentation.
</Note>

## Overview

Streams v2 is a major upgrade that provides:

- **Unlimited stream length** (previously capped at 2000 chunks)
- **Unlimited active streams per run** (previously 5)
- **Improved reliability** with automatic resumption on connection loss
- **28-day stream retention** (previously 1 day)
- **Multiple client streams** can pipe to a single stream
- **Enhanced dashboard visibility** for viewing stream data in real-time

## Enabling Streams v2

Streams v2 is **automatically enabled** when triggering runs from the SDK using 4.1.0 or later. If you aren't triggering via the SDK, you'll need to explicitly enable v2 streams via setting the `x-trigger-realtime-streams-version=v2` header when triggering the task.

If you'd like to **opt-out** of the v2 streams, you can see so in one of the following two ways:

### Option 1: Configure the SDK

```ts
import { auth } from "@trigger.dev/sdk";

auth.configure({
  future: {
    v2RealtimeStreams: false,
  },
});
```

### Option 2: Environment Variable

Set the `TRIGGER_V2_REALTIME_STREAMS=0` environment variable in your backend code (where you trigger tasks).

## Limits Comparison

| Limit                            | Streams v1 | Streams v2 |
| -------------------------------- | ---------- | ---------- |
| Maximum stream length            | 2000       | Unlimited  |
| Number of active streams per run | 5          | Unlimited  |
| Maximum streams per run          | 10         | Unlimited  |
| Maximum stream TTL               | 1 day      | 28 days    |
| Maximum stream size              | 10MB       | 300 MiB    |

## Quick Start

The recommended workflow for using Realtime Streams v2:

1. **Define your streams** in a shared location using `streams.define()`
2. **Use the defined stream** in your tasks with `.pipe()`, `.append()`, or `.writer()`
3. **Read from the stream** using `.read()` or the `useRealtimeStream` hook in React

This approach gives you full type safety, better code organization, and easier maintenance as your application grows.

## Defining Typed Streams (Recommended)

The recommended way to work with streams is to define them once with `streams.define()`. This allows you to specify the chunk type and stream ID in one place, and then reuse that definition throughout your codebase with full type safety.

### Creating a Defined Stream

Define your streams in a shared location (like `app/streams.ts` or `trigger/streams.ts`):

```ts
import { streams, InferStreamType } from "@trigger.dev/sdk";

// Define a stream with a specific type
export const aiStream = streams.define<string>({
  id: "ai-output",
});

// Export the type for use in frontend components
export type AIStreamPart = InferStreamType<typeof aiStream>;
```

You can define streams for any JSON-serializable type:

```ts
import { streams, InferStreamType } from "@trigger.dev/sdk";
import { UIMessageChunk } from "ai";

// Stream for AI UI message chunks
export const aiStream = streams.define<UIMessageChunk>({
  id: "ai",
});

// Stream for progress updates
export const progressStream = streams.define<{ step: string; percent: number }>({
  id: "progress",
});

// Stream for simple text
export const logStream = streams.define<string>({
  id: "logs",
});

// Export types
export type AIStreamPart = InferStreamType<typeof aiStream>;
export type ProgressStreamPart = InferStreamType<typeof progressStream>;
export type LogStreamPart = InferStreamType<typeof logStream>;
```

### Using Defined Streams in Tasks

Once defined, you can use all stream methods on your defined stream:

```ts
import { task } from "@trigger.dev/sdk";
import { aiStream } from "./streams";

export const streamTask = task({
  id: "stream-task",
  run: async (payload: { prompt: string }) => {
    // Get a stream from an AI service, database, etc.
    const stream = await getAIStream(payload.prompt);

    // Pipe the stream using your defined stream
    const { stream: readableStream, waitUntilComplete } = aiStream.pipe(stream);

    // Option A: Iterate over the stream locally
    for await (const chunk of readableStream) {
      console.log("Received chunk:", chunk);
    }

    // Option B: Wait for the stream to complete
    await waitUntilComplete();

    return { message: "Stream completed" };
  },
});
```

#### Reading from a Stream

Use the defined stream's `read()` method to consume data from anywhere (frontend, backend, or another task):

```ts
import { aiStream } from "./streams";

const stream = await aiStream.read(runId);

for await (const chunk of stream) {
  console.log(chunk); // chunk is typed as the stream's chunk type
}
```

With options:

```ts
const stream = await aiStream.read(runId, {
  timeoutInSeconds: 60, // Stop if no data for 60 seconds
  startIndex: 10, // Start from the 10th chunk
});
```

#### Appending to a Stream

Use the defined stream's `append()` method to add a single chunk:

```ts
import { task } from "@trigger.dev/sdk";
import { aiStream, progressStream, logStream } from "./streams";

export const appendTask = task({
  id: "append-task",
  run: async (payload) => {
    // Append to different streams with full type safety
    await logStream.append("Processing started");
    await progressStream.append({ step: "Initialization", percent: 0 });

    // Do some work...

    await progressStream.append({ step: "Processing", percent: 50 });
    await logStream.append("Step 1 complete");

    // Do more work...

    await progressStream.append({ step: "Complete", percent: 100 });
    await logStream.append("All steps complete");
  },
});
```

#### Writing Multiple Chunks

Use the defined stream's `writer()` method for more complex stream writing:

```ts
import { task } from "@trigger.dev/sdk";
import { logStream } from "./streams";

export const writerTask = task({
  id: "writer-task",
  run: async (payload) => {
    const { waitUntilComplete } = logStream.writer({
      execute: ({ write, merge }) => {
        // Write individual chunks
        write("Chunk 1");
        write("Chunk 2");

        // Merge another stream
        const additionalStream = ReadableStream.from(["Chunk 3", "Chunk 4", "Chunk 5"]);
        merge(additionalStream);
      },
    });

    await waitUntilComplete();
  },
});
```

### Using Defined Streams in React

Defined streams work seamlessly with the `useRealtimeStream` hook:

```tsx
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/app/streams";

export function StreamViewer({ accessToken, runId }: { accessToken: string; runId: string }) {
  // Pass the defined stream directly - full type safety!
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken,
    timeoutInSeconds: 600,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

## Direct Stream Methods (Without Defining)

<Warning>
  We strongly recommend using `streams.define()` instead of direct methods. Defined streams provide
  better organization, full type safety, and make it easier to maintain your codebase as it grows.
</Warning>

If you have a specific reason to avoid defined streams, you can use stream methods directly by specifying the stream key each time.

### Direct Piping

```ts
import { streams, task } from "@trigger.dev/sdk";

export const directStreamTask = task({
  id: "direct-stream",
  run: async (payload: { prompt: string }) => {
    const stream = await getAIStream(payload.prompt);

    // Specify the stream key directly
    const { stream: readableStream, waitUntilComplete } = streams.pipe("ai-output", stream);

    await waitUntilComplete();
  },
});
```

### Direct Reading

```ts
import { streams } from "@trigger.dev/sdk";

// Specify the stream key when reading
const stream = await streams.read(runId, "ai-output");

for await (const chunk of stream) {
  console.log(chunk);
}
```

### Direct Appending

```ts
import { streams, task } from "@trigger.dev/sdk";

export const directAppendTask = task({
  id: "direct-append",
  run: async (payload) => {
    // Specify the stream key each time
    await streams.append("logs", "Processing started");
    await streams.append("progress", "50%");
    await streams.append("logs", "Complete");
  },
});
```

### Direct Writing

```ts
import { streams, task } from "@trigger.dev/sdk";

export const directWriterTask = task({
  id: "direct-writer",
  run: async (payload) => {
    const { waitUntilComplete } = streams.writer("output", {
      execute: ({ write, merge }) => {
        write("Chunk 1");
        write("Chunk 2");
      },
    });

    await waitUntilComplete();
  },
});
```

## Default Stream

Every run has a "default" stream, allowing you to skip the stream key entirely. This is useful for simple cases where you only need one stream per run.

Using direct methods:

```ts
import { streams, task } from "@trigger.dev/sdk";

export const defaultStreamTask = task({
  id: "default-stream",
  run: async (payload) => {
    const stream = getDataStream();

    // No stream key needed - uses "default"
    const { waitUntilComplete } = streams.pipe(stream);

    await waitUntilComplete();
  },
});

// Reading from the default stream
const readStream = await streams.read(runId);
```

## Targeting Different Runs

You can pipe streams to parent, root, or any other run using the `target` option. This works with both defined streams and direct methods.

### With Defined Streams

```ts
import { task } from "@trigger.dev/sdk";
import { logStream } from "./streams";

export const childTask = task({
  id: "child-task",
  run: async (payload, { ctx }) => {
    const stream = getDataStream();

    // Pipe to parent run
    logStream.pipe(stream, { target: "parent" });

    // Pipe to root run
    logStream.pipe(stream, { target: "root" });

    // Pipe to self (default behavior)
    logStream.pipe(stream, { target: "self" });

    // Pipe to a specific run ID
    logStream.pipe(stream, { target: payload.otherRunId });
  },
});
```

### With Direct Methods

```ts
import { streams, task } from "@trigger.dev/sdk";

export const childTask = task({
  id: "child-task",
  run: async (payload, { ctx }) => {
    const stream = getDataStream();

    // Pipe to parent run
    streams.pipe("output", stream, { target: "parent" });

    // Pipe to root run
    streams.pipe("output", stream, { target: "root" });

    // Pipe to a specific run ID
    streams.pipe("output", stream, { target: payload.otherRunId });
  },
});
```

## Streaming from Outside a Task

If you specify a `target` run ID, you can pipe streams from anywhere (like a Next.js API route):

```ts
import { streams } from "@trigger.dev/sdk";
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

export async function POST(req: Request) {
  const { messages, runId } = await req.json();

  const result = streamText({
    model: openai("gpt-4o"),
    messages,
  });

  // Pipe AI stream to a Trigger.dev run
  const { stream } = streams.pipe("ai-stream", result.toUIMessageStream(), {
    target: runId,
  });

  return new Response(stream as any, {
    headers: { "Content-Type": "text/event-stream" },
  });
}
```

## React Hook

Use the `useRealtimeStream` hook to subscribe to streams in your React components.

### With Defined Streams (Recommended)

```tsx
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/app/streams";

export function StreamViewer({ accessToken, runId }: { accessToken: string; runId: string }) {
  // Pass the defined stream directly for full type safety
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken,
    timeoutInSeconds: 600,
    onData: (chunk) => {
      console.log("New chunk:", chunk); // chunk is typed!
    },
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

### With Direct Stream Keys

If you prefer not to use defined streams, you can specify the stream key directly:

```tsx
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";

export function StreamViewer({ accessToken, runId }: { accessToken: string; runId: string }) {
  const { parts, error } = useRealtimeStream<string>(runId, "ai-output", {
    accessToken,
    timeoutInSeconds: 600,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div>
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

### Using Default Stream

```tsx
// Omit stream key to use the default stream
const { parts, error } = useRealtimeStream<string>(runId, {
  accessToken,
});
```

### Hook Options

```tsx
const { parts, error } = useRealtimeStream(streamDef, runId, {
  accessToken: "pk_...", // Required: Public access token
  baseURL: "https://api.trigger.dev", // Optional: Custom API URL
  timeoutInSeconds: 60, // Optional: Timeout (default: 60)
  startIndex: 0, // Optional: Start from specific chunk
  throttleInMs: 16, // Optional: Throttle updates (default: 16ms)
  onData: (chunk) => {}, // Optional: Callback for each chunk
});
```

## AI SDK `useChat` transport with Trigger.dev tasks

If you want to use AI SDK UI's `useChat()` on the frontend and run the backend as a Trigger.dev task,
use the `@trigger.dev/ai` transport.

### Install

```bash
npm add @trigger.dev/ai @ai-sdk/react ai
```

### Define a typed stream

```ts
// app/streams.ts
import { streams } from "@trigger.dev/sdk";
import { UIMessageChunk } from "ai";

export const aiStream = streams.define<UIMessageChunk>({
  id: "ai",
});
```

### Create a task that accepts rich chat transport payload

```ts
// trigger/chat-task.ts
import { openai } from "@ai-sdk/openai";
import type { TriggerChatTransportPayload } from "@trigger.dev/ai";
import { task } from "@trigger.dev/sdk";
import { convertToModelMessages, streamText, UIMessage } from "ai";
import { aiStream } from "@/app/streams";

type ChatPayload = TriggerChatTransportPayload<UIMessage>;

export const aiChatTask = task({
  id: "ai-chat",
  run: async (payload: ChatPayload) => {
    const result = streamText({
      model: openai("gpt-4o"),
      messages: convertToModelMessages(payload.messages),
    });

    const { waitUntilComplete } = aiStream.pipe(result.toUIMessageStream());
    await waitUntilComplete();
  },
});
```

### Use `useChat()` with Trigger chat transport

```tsx
"use client";

import { useChat } from "@ai-sdk/react";
import { TriggerChatTransport } from "@trigger.dev/ai";
import { aiStream } from "@/app/streams";

export function Chat({ triggerToken }: { triggerToken: string }) {
  const chat = useChat({
    transport: new TriggerChatTransport({
      task: "ai-chat",
      stream: aiStream,
      accessToken: triggerToken,
      timeoutInSeconds: 120,
    }),
  });

  return (
    <form
      onSubmit={(event) => {
        event.preventDefault();
        chat.sendMessage({ text: "Hello!" });
      }}
    >
      <button type="submit">Send</button>
    </form>
  );
}
```

The default payload sent to your task is a rich, typed object that includes:

- `chatId`
- `trigger` (`"submit-message"` or `"regenerate-message"`)
- `messageId`
- `messages`
- `request` (`headers`, `body`, and `metadata`)

### Advanced transport options

`TriggerChatTransport` also supports:

- `payloadMapper` (sync or async) for custom task payload shapes
- `triggerOptions` as an object or resolver function (sync or async)
- `runStore` for custom reconnect-state persistence (including async stores)
- `onTriggeredRun` callback (sync or async) to persist or observe run IDs
- `onError` callback to observe non-fatal transport issues
- headers passed through transport can be object, `Headers`, or tuple arrays

`onError` receives phase-aware details (`payloadMapper`, `triggerOptions`, `triggerTask`,
`streamSubscribe`, `onTriggeredRun`, `consumeTrackingStream`, `reconnect`) plus `chatId`,
optional `runId`, and the underlying `error` (non-Error throws are normalized to `Error`
instances).

Run-store cleanup is handled as best effort, and cleanup failures won't mask the original
transport failure that triggered `onError`. Cleanup still attempts both persistence steps
(`set` inactive state and `delete`) even when one step fails.

```ts
import type { TriggerChatRunState, TriggerChatRunStore } from "@trigger.dev/ai";

class MemoryRunStore implements TriggerChatRunStore {
  private runs = new Map<string, TriggerChatRunState>();

  async get(chatId: string) {
    return this.runs.get(chatId);
  }

  async set(state: TriggerChatRunState) {
    this.runs.set(state.chatId, state);
  }

  async delete(chatId: string) {
    this.runs.delete(chatId);
  }
}
```

`reconnectToStream()` only resumes active streams. When a stream completes or errors,
the transport clears stored run state and future reconnect attempts return `null`.
If stale inactive reconnect state cannot be cleaned up, reconnect still returns `null` and
the failure is surfaced through `onError` with phase `reconnect`.
Subsequent reconnect calls will retry stale inactive-state cleanup until it succeeds.
If `onError` is omitted, reconnect still returns `null` and continues without callback reporting.

`baseURL` defaults to `https://api.trigger.dev` when omitted.
It supports optional path prefixes and trailing slashes; both trigger and stream URLs
are normalized consistently, surrounding whitespace is trimmed before normalization, and
the resulting value must not be empty. The value must also be a valid absolute URL using
the `http` or `https` protocol, without query parameters, hash fragments, or embedded
username/password credentials.
Protocol matching is case-insensitive (`HTTP://...` and `HTTPS://...` are accepted).

Examples:

- ✅ `https://api.trigger.dev`
- ✅ `https://api.trigger.dev/custom-prefix`
- ✅ `  https://api.trigger.dev/custom-prefix///   ` (trimmed + normalized)
- ✅ `\n\thttps://api.trigger.dev/custom-prefix/\t\n` (newline/tab wrappers trimmed)
- ✅ `https://api.trigger.dev/custom%20prefix` (percent-encoded whitespace)
- ✅ `https://api.trigger.dev/custom%3Fprefix%23segment` (percent-encoded `?` / `#`)
- ✅ `\u00A0https://api.trigger.dev/custom-prefix/\u00A0` (non-breaking-space wrapper trimmed)
- ✅ `\u1680https://api.trigger.dev/custom-prefix/\u1680` (ogham-space-mark wrapper trimmed)
- ✅ `\u2007https://api.trigger.dev/custom-prefix/\u2007` (figure-space wrapper trimmed)
- ✅ `\u200Ahttps://api.trigger.dev/custom-prefix/\u200A` (hair-space wrapper trimmed)
- ✅ `\u2009https://api.trigger.dev/custom-prefix/\u2009` (thin-space wrapper trimmed)
- ✅ `\u2008https://api.trigger.dev/custom-prefix/\u2008` (punctuation-space wrapper trimmed)
- ✅ `\u2006https://api.trigger.dev/custom-prefix/\u2006` (six-per-em-space wrapper trimmed)
- ✅ `\u2003https://api.trigger.dev/custom-prefix/\u2003` (em-space wrapper trimmed)
- ✅ `\u205Fhttps://api.trigger.dev/custom-prefix/\u205F` (medium-mathematical-space wrapper trimmed)
- ✅ `\u3000https://api.trigger.dev/custom-prefix/\u3000` (ideographic-space wrapper trimmed)
- ✅ `\uFEFFhttps://api.trigger.dev/custom-prefix/\uFEFF` (BOM wrapper trimmed)
- ❌ `\u2060https://api.trigger.dev/custom-prefix/\u2060` (word-joiner wrappers are rejected)
- ❌ `\u200Bhttps://api.trigger.dev/custom-prefix/\u200B` (zero-width-space wrappers are rejected)
- ❌ `\u200Chttps://api.trigger.dev/custom-prefix/\u200C` (zero-width-non-joiner wrappers are rejected)
- ❌ `\u200Dhttps://api.trigger.dev/custom-prefix/\u200D` (zero-width-joiner wrappers are rejected)
- ❌ `\u180Ehttps://api.trigger.dev/custom-prefix/\u180E` (mongolian-vowel-separator wrappers are rejected)
- ❌ `https://api.trigger.dev?foo=bar`
- ❌ `https://api.trigger.dev#fragment`
- ❌ `https://user:pass@api.trigger.dev`
- ❌ `ftp://api.trigger.dev`
- ❌ `ws://api.trigger.dev` / `wss://api.trigger.dev`
- ❌ `\u1680///\u1680` (empty after trimming wrapper whitespace)
- ❌ `\u2007///\u2007` (empty after trimming wrapper whitespace)
- ❌ `\u205F///\u205F` (empty after trimming wrapper whitespace)
- ❌ `\u180E///\u180E` (rejected as internal invisible-separator whitespace)
- ❌ `\u3000///\u3000` (empty after trimming wrapper whitespace)
- ❌ `\n\thttps://api.trigger.dev/base/?query=1\t\n` (query is still rejected after trimming wrappers)
- ❌ `\n\thttps://api.trigger.dev/base/#fragment\t\n` (hash is still rejected after trimming wrappers)
- ❌ `\n\thttps://user:pass@api.trigger.dev/base/\t\n` (credentials are still rejected after trimming wrappers)
- ❌ `\n\tws://api.trigger.dev\t\n` / `\n\twss://api.trigger.dev\t\n` (trimmed wrappers still reject websocket protocols)
- ❌ `https://api.trigger.dev/\ninternal`
- ❌ `https://api.trigger.dev/in valid`
- ❌ `https://api.trigger.dev/\tinternal`
- ❌ `https://api.trigger.dev/\vinternal`
- ❌ `https://api.trigger.dev/\finternal`
- ❌ `https://api.trigger.dev/\rinternal`
- ❌ `https://api.trigger.dev/\u200Binternal`
- ❌ `https://api.trigger.dev/\u200Cinternal`
- ❌ `https://api.trigger.dev/\u200Dinternal`
- ❌ `https://api.trigger.dev/\u1680internal`
- ❌ `https://api.trigger.dev/\u2007internal`
- ❌ `https://api.trigger.dev/\u200Ainternal`
- ❌ `https://api.trigger.dev/\u2009internal`
- ❌ `https://api.trigger.dev/\u2008internal`
- ❌ `https://api.trigger.dev/\u2006internal`
- ❌ `https://api.trigger.dev/\u2003internal`
- ❌ `https://api.trigger.dev/\u202Finternal`
- ❌ `https://api.trigger.dev/\u205Finternal`
- ❌ `https://api.trigger.dev/\u180Einternal`
- ❌ `https://api.trigger.dev/\u3000internal`
- ❌ `https://api.trigger.dev/\u2028internal`
- ❌ `https://api.trigger.dev/\u2029internal`
- ❌ `https://api.trigger.dev/\u2060internal`
- ❌ `https://api.trigger.dev/\uFEFFinternal`

Validation errors use these exact messages:

- `baseURL must not be empty`
- `baseURL must be a valid absolute URL`
- `baseURL must not contain internal whitespace characters`
- `baseURL must use http or https protocol`
- `baseURL must not include query parameters or hash fragments`
- `baseURL must not include username or password credentials`

The internal-whitespace error also applies to invisible separator characters
like `\u200B`, `\u200C`, `\u200D`, `\u2060`, and `\uFEFF`.

When multiple issues are present, validation order is deterministic:
internal whitespace → protocol → query/hash → credentials.

Examples of ordering:

- `ftp://example.com?x=1` → `baseURL must use http or https protocol`
- `https://user:pass@example.com?x=1` → `baseURL must not include query parameters or hash fragments`
- `ftp://user:pass@example.com/in valid?x=1` → `baseURL must not contain internal whitespace characters`
- `ftp://user:pass@example.com/\u2060invalid?x=1#fragment` → `baseURL must not contain internal whitespace characters`
- `ftp://user:pass@example.com/\u180Einvalid?x=1#fragment` → `baseURL must not contain internal whitespace characters`

For richer TypeScript ergonomics in app code, `@trigger.dev/ai` also exports:

- `TriggerChatHeadersInput`
- `TriggerChatSendMessagesOptions`
- `TriggerChatReconnectOptions`

## Complete Example: AI Streaming

### Define the stream

```ts
// app/streams.ts
import { streams, InferStreamType } from "@trigger.dev/sdk";
import { UIMessageChunk } from "ai";

export const aiStream = streams.define<UIMessageChunk>({
  id: "ai",
});

export type AIStreamPart = InferStreamType<typeof aiStream>;
```

### Create the task

```ts
// trigger/ai-task.ts
import { task } from "@trigger.dev/sdk";
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";
import { aiStream } from "@/app/streams";

export const generateAI = task({
  id: "generate-ai",
  run: async (payload: { prompt: string }) => {
    const result = streamText({
      model: openai("gpt-4o"),
      prompt: payload.prompt,
    });

    const { waitUntilComplete } = aiStream.pipe(result.toUIMessageStream());

    await waitUntilComplete();

    return { success: true };
  },
});
```

### Frontend component

```tsx
// components/ai-stream.tsx
"use client";

import { useRealtimeStream } from "@trigger.dev/react-hooks";
import { aiStream } from "@/app/streams";

export function AIStream({ accessToken, runId }: { accessToken: string; runId: string }) {
  const { parts, error } = useRealtimeStream(aiStream, runId, {
    accessToken,
    timeoutInSeconds: 300,
  });

  if (error) return <div>Error: {error.message}</div>;
  if (!parts) return <div>Loading...</div>;

  return (
    <div className="prose">
      {parts.map((part, i) => (
        <span key={i}>{part}</span>
      ))}
    </div>
  );
}
```

## Migration from v1

If you're using the old `metadata.stream()` API, here's how to migrate to the recommended v2 approach:

### Step 1: Define Your Streams

Create a shared streams definition file:

```ts
// app/streams.ts or trigger/streams.ts
import { streams, InferStreamType } from "@trigger.dev/sdk";

export const myStream = streams.define<string>({
  id: "my-stream",
});

export type MyStreamPart = InferStreamType<typeof myStream>;
```

### Step 2: Update Your Tasks

Replace `metadata.stream()` with the defined stream's `pipe()` method:

```ts
// Before (v1)
import { metadata, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload) => {
    const stream = getDataStream();
    await metadata.stream("my-stream", stream);
  },
});
```

```ts
// After (v2 - Recommended)
import { task } from "@trigger.dev/sdk";
import { myStream } from "./streams";

export const myTask = task({
  id: "my-task",
  run: async (payload) => {
    const stream = getDataStream();

    // Don't await - returns immediately
    const { waitUntilComplete } = myStream.pipe(stream);

    // Optionally wait for completion
    await waitUntilComplete();
  },
});
```

### Step 3: Update Your Frontend

Use the defined stream with `useRealtimeStream`:

```tsx
// Before
const { parts, error } = useRealtimeStream<string>(runId, "my-stream", {
  accessToken,
});
```

```tsx
// After
import { myStream } from "@/app/streams";

const { parts, error } = useRealtimeStream(myStream, runId, {
  accessToken,
});
```

### Alternative: Direct Methods (Not Recommended)

If you prefer not to use defined streams, you can use direct methods:

```ts
import { streams, task } from "@trigger.dev/sdk";

export const myTask = task({
  id: "my-task",
  run: async (payload) => {
    const stream = getDataStream();
    const { waitUntilComplete } = streams.pipe("my-stream", stream);
    await waitUntilComplete();
  },
});
```

## Reliability Features

Streams v2 includes automatic reliability improvements:

- **Automatic resumption**: If a connection is lost, both appending and reading will automatically resume from the last successful chunk
- **No data loss**: Network issues won't cause stream data to be lost
- **Idempotent operations**: Duplicate chunks are automatically handled

These improvements happen automatically - no code changes needed.

## Dashboard Integration

Streams are now visible in the Trigger.dev dashboard, allowing you to:

- View stream data in real-time as it's generated
- Inspect historical stream data for completed runs
- Debug streaming issues with full visibility into chunk delivery

<video src="https://content.trigger.dev/streams-v2-dashboard.mp4" controls muted autoPlay loop />

## Best Practices

1. **Always use `streams.define()`**: Define your streams in a shared location for better organization, type safety, and code reusability. This is the recommended approach for all streams.
2. **Export stream types**: Use `InferStreamType` to export types for your frontend components
3. **Handle errors gracefully**: Always check for errors when reading streams in your UI
4. **Set appropriate timeouts**: Adjust `timeoutInSeconds` based on your use case (AI completions may need longer timeouts)
5. **Target parent runs**: When orchestrating with child tasks, pipe to parent runs for easier consumption
6. **Throttle frontend updates**: Use `throttleInMs` in `useRealtimeStream` to prevent excessive re-renders
7. **Use descriptive stream IDs**: Choose clear, descriptive IDs like `"ai-output"` or `"progress"` instead of generic names

## Troubleshooting

### Stream not appearing in dashboard

- Ensure you've enabled Streams v2 via the future flag or environment variable
- Verify your task is actually writing to the stream
- Check that the stream key matches between writing and reading

### Stream timeout errors

- Increase `timeoutInSeconds` in your `read()` or `useRealtimeStream()` calls
- Ensure your stream source is actively producing data
- Check network connectivity between your application and Trigger.dev

### Missing chunks

- With v2, chunks should never be lost due to automatic resumption
- Verify you're reading from the correct stream key
- Check the `startIndex` option if you're not seeing expected chunks
